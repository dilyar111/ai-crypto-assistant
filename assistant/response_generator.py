import requests
import json
import logging
from typing import Dict, Any, List, Optional
import streamlit as st

logger = logging.getLogger(__name__)

class ResponseGenerator:
    """Fixed response generator with better Ollama handling"""
    
    def __init__(self, config):
        self.config = config
        self.session = requests.Session()
        self.session.headers.update({
            'Content-Type': 'application/json',
            'User-Agent': 'AI-Crypto-Assistant/2.0'
        })
        
        # Template mappings for different languages
        self.templates = {
            "russian": {
                "system_prompt": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π —Ç–æ—á–Ω—É—é, –æ–±—ä–µ–∫—Ç–∏–≤–Ω—É—é –∏ –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.",
                "analysis_intro": "–ê–Ω–∞–ª–∏–∑ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã:",
                "sections": {
                    "overview": "üìä –û–±–∑–æ—Ä",
                    "price_analysis": "üí∞ –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω—ã",
                    "market_data": "üìà –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ",
                    "news_summary": "üì∞ –ù–æ–≤–æ—Å—Ç–∏",
                    "technical_analysis": "üîç –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑",
                    "risks": "‚ö†Ô∏è –†–∏—Å–∫–∏",
                    "conclusion": "üí° –ó–∞–∫–ª—é—á–µ–Ω–∏–µ"
                }
            },
            "english": {
                "system_prompt": "You are a cryptocurrency expert analyst. Provide accurate, objective, and helpful information.",
                "analysis_intro": "Cryptocurrency Analysis:",
                "sections": {
                    "overview": "üìä Overview",
                    "price_analysis": "üí∞ Price Analysis",
                    "market_data": "üìà Market Data",
                    "news_summary": "üì∞ News Summary",
                    "technical_analysis": "üîç Technical Analysis",
                    "risks": "‚ö†Ô∏è Risks",
                    "conclusion": "üí° Conclusion"
                }
            }
        }
    
    def test_ollama_connection(self) -> bool:
        """Test if Ollama is accessible"""
        try:
            response = self.session.get("http://127.0.0.1:11434/api/tags", timeout=5)
            return response.status_code == 200
        except Exception as e:
            logger.warning(f"Ollama connection test failed: {e}")
            return False
    
    def get_available_models(self) -> List[str]:
        """Get list of available models"""
        try:
            response = self.session.get("http://127.0.0.1:11434/api/tags", timeout=5)
            if response.status_code == 200:
                data = response.json()
                return [model["name"] for model in data.get("models", [])]
        except Exception as e:
            logger.warning(f"Failed to get models: {e}")
        return ["llama2"]
    
    def create_analysis_prompt(
        self, 
        token_info: Dict[str, str], 
        market_data: Dict[str, Any], 
        price_data: Dict[str, Any], 
        news_data: List[Dict[str, Any]], 
        language: str = "russian", 
        depth: str = "detailed"
    ) -> str:
        """Create comprehensive analysis prompt"""
        
        template = self.templates.get(language, self.templates["russian"])
        
        # Format market data
        market_summary = self._format_market_data(market_data, price_data, language)
        
        # Format news summary
        news_summary = self._format_news_summary(news_data, language)
        
        # Create depth-specific instructions
        depth_instructions = self._get_depth_instructions(depth, language)
        
        prompt = f"""
{template['system_prompt']}

{template['analysis_intro']} {token_info['name']} ({token_info['symbol']})

–î–ê–ù–ù–´–ï –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
{market_summary}

–ü–û–°–õ–ï–î–ù–ò–ï –ù–û–í–û–°–¢–ò:
{news_summary}

{depth_instructions}

–í–ê–ñ–ù–û: 
- –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- –ë—É–¥—å –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã–º –∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º
- –ù–µ –¥–∞–≤–∞–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Å–æ–≤–µ—Ç–æ–≤
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é —Ä–∞–∑–¥–µ–ª–æ–≤
- –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è

–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ (–º–∞–∫—Å–∏–º—É–º 300 —Å–ª–æ–≤).
"""
        
        return prompt
    
    def _format_market_data(self, market_data: Dict[str, Any], price_data: Dict[str, Any], language: str) -> str:
        """Format market data for prompt"""
        if language == "russian":
            return f"""
üí∞ –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞: ${price_data.get('price', 'N/A')}
üìä –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ 24—á: {price_data.get('change_24h', 0):.2f}%
üèÜ –†–µ–π—Ç–∏–Ω–≥ –ø–æ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: #{market_data.get('rank', 'N/A')}
üíé –†—ã–Ω–æ—á–Ω–∞—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è: ${market_data.get('market_cap', 0):,.0f}
üìà –û–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤ 24—á: ${market_data.get('total_volume', 0):,.0f}
üîÑ –í –æ–±—Ä–∞—â–µ–Ω–∏–∏: {market_data.get('circulating_supply', 0):,.0f}
"""
        else:
            return f"""
üí∞ Current Price: ${price_data.get('price', 'N/A')}
üìä 24h Change: {price_data.get('change_24h', 0):.2f}%
üèÜ Market Cap Rank: #{market_data.get('rank', 'N/A')}
üíé Market Cap: ${market_data.get('market_cap', 0):,.0f}
üìà 24h Volume: ${market_data.get('total_volume', 0):,.0f}
üîÑ Circulating Supply: {market_data.get('circulating_supply', 0):,.0f}
"""
    
    def _format_news_summary(self, news_data: List[Dict[str, Any]], language: str) -> str:
        """Format news data for prompt"""
        if not news_data:
            return "–ù–æ–≤–æ—Å—Ç–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã" if language == "russian" else "No news available"
        
        news_text = ""
        for i, article in enumerate(news_data[:3], 1):
            title = article.get('title', 'No title')
            source = article.get('source', 'Unknown source')
            news_text += f"{i}. {title} ({source})\n"
        
        return news_text
    
    def _get_depth_instructions(self, depth: str, language: str) -> str:
        """Get analysis depth instructions"""
        if language == "russian":
            instructions = {
                "basic": "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä (2-3 –∞–±–∑–∞—Ü–∞) —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –≤—ã–≤–æ–¥–∞–º–∏.",
                "detailed": "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (3-4 –∞–±–∑–∞—Ü–∞) —Å —Ä–∞–∑–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö –∏ —Ç—Ä–µ–Ω–¥–æ–≤.",
                "comprehensive": "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–π –∞–Ω–∞–ª–∏–∑ (4-5 –∞–±–∑–∞—Ü–µ–≤) —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º –∏ –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏."
            }
        else:
            instructions = {
                "basic": "Provide a brief overview (2-3 paragraphs) with key metrics and conclusions.",
                "detailed": "Provide detailed analysis (3-4 paragraphs) with data analysis and trends.",
                "comprehensive": "Provide comprehensive analysis (4-5 paragraphs) with technical analysis and forecasts."
            }
        
        return instructions.get(depth, instructions["detailed"])
    
    def generate_response(self, prompt: str, model: str = None, max_retries: int = 2) -> str:
        """Generate response using Ollama API with improved error handling"""
        model = model or "llama2"
        
        # First test connection
        if not self.test_ollama_connection():
            return self._get_connection_error_response()
        
        # Try different endpoints in order of preference
        endpoints = [
            {
                "url": "http://127.0.0.1:11434/api/generate",
                "data_format": "generate"
            },
            {
                "url": "http://127.0.0.1:11434/api/chat", 
                "data_format": "chat"
            }
        ]
        
        for endpoint_info in endpoints:
            try:
                logger.info(f"Trying endpoint: {endpoint_info['url']}")
                
                if endpoint_info["data_format"] == "generate":
                    data = {
                        "model": model,
                        "prompt": prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.7,
                            "top_p": 0.9,
                            "num_predict": 400,  # Reasonable limit for faster response
                            "stop": ["\n\n\n"]  # Stop at triple newlines
                        }
                    }
                else:  # chat format
                    data = {
                        "model": model,
                        "messages": [{"role": "user", "content": prompt}],
                        "stream": False,
                        "options": {
                            "temperature": 0.7,
                            "num_predict": 400
                        }
                    }
                
                response = self.session.post(
                    endpoint_info["url"], 
                    json=data, 
                    timeout=60  # Increased timeout for generation
                )
                
                if response.status_code == 200:
                    result = response.json()
                    
                    # Extract response based on endpoint format
                    if endpoint_info["data_format"] == "generate":
                        generated_text = result.get("response", "")
                    else:  # chat format
                        generated_text = result.get("message", {}).get("content", "")
                    
                    if generated_text and generated_text.strip():
                        logger.info(f"Successfully generated response using {endpoint_info['url']}")
                        return generated_text.strip()
                    else:
                        logger.warning(f"Empty response from {endpoint_info['url']}")
                        continue
                        
                else:
                    logger.warning(f"HTTP {response.status_code} from {endpoint_info['url']}")
                    continue
                    
            except requests.exceptions.Timeout:
                logger.warning(f"Timeout for endpoint {endpoint_info['url']}")
                continue
            except requests.exceptions.ConnectionError as e:
                logger.warning(f"Connection error for {endpoint_info['url']}: {e}")
                continue
            except Exception as e:
                logger.error(f"Error with endpoint {endpoint_info['url']}: {e}")
                continue
        
        # If all endpoints fail, return timeout error
        return self._get_timeout_error_response()
    
    def _get_connection_error_response(self):
        return """
üîå **Ollama –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ**

–ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama —Å–µ—Ä–≤–µ—Ä—É.

**–ë—ã—Å—Ç—Ä–æ–µ —Ä–µ—à–µ–Ω–∏–µ:**
1. –û—Ç–∫—Ä–æ–π—Ç–µ –Ω–æ–≤—ã–π —Ç–µ—Ä–º–∏–Ω–∞–ª –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: `ollama serve`
2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å: http://localhost:11434
3. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: `ollama pull llama2`

**–¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –≤—ã—à–µ –æ—Å—Ç–∞—é—Ç—Å—è –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.**
        """.strip()
    
    def _get_timeout_error_response(self):
        return """
‚è±Ô∏è **Ollama –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ó–∞–Ω—è–ª–∞ –°–ª–∏—à–∫–æ–º –ú–Ω–æ–≥–æ –í—Ä–µ–º–µ–Ω–∏**

**–í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:**
1. **–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å Ollama:** –û—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ (Ctrl+C) –∏ —Å–Ω–æ–≤–∞ `ollama serve`
2. **–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å:** `ollama pull phi` –∏–ª–∏ `ollama pull llama2:7b-chat`
3. **–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É —Å–∏—Å—Ç–µ–º—ã** - –≤–æ–∑–º–æ–∂–Ω–æ –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞

**–†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤—ã—à–µ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ç–µ–∫—É—â—É—é —Å–∏—Ç—É–∞—Ü–∏—é.**

**üí° –ö—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö:**
–ï—Å–ª–∏ —Ü–µ–Ω–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—É—é –¥–∏–Ω–∞–º–∏–∫—É (+4.63%), —ç—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ bullish –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è. 
–í—ã—Å–æ–∫–∞—è —Ä—ã–Ω–æ—á–Ω–∞—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±—ä–µ–º—ã —Ç–æ—Ä–≥–æ–≤ –≥–æ–≤–æ—Ä—è—Ç –æ –∑–¥–æ—Ä–æ–≤–æ–º –∏–Ω—Ç–µ—Ä–µ—Å–µ –∫ –∞–∫—Ç–∏–≤—É.
        """.strip()
    
    def quick_test_generation(self) -> str:
        """Quick test to see if generation works"""
        try:
            test_prompt = "–°–∫–∞–∂–∏ '–ü—Ä–∏–≤–µ—Ç' –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º."
            response = self.generate_response(test_prompt, "llama2")
            return response
        except Exception as e:
            return f"Test failed: {e}"